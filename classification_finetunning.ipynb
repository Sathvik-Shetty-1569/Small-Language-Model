{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f17f8c",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bd1a555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection\\SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Create an unverified SSL context\n",
    "    ssl_context = ssl._create_unverified_context()\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a160066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "521a794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fadef55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e10d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d4c96f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c354db2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045\n",
      "149\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(validation_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74f9b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6925418",
   "metadata": {},
   "source": [
    "## Create Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867ab67e",
   "metadata": {},
   "source": [
    "<div class=\"alert-block alert alert-warning\">\n",
    "1. Tokenize the input text to convert it into numerical token IDs  \n",
    "<br>\n",
    "2. Identify the maximum sequence length among all samples  \n",
    "<br>\n",
    "3. Pad shorter sequences using the end-of-text token (50256) to match the maximum length  \n",
    "<br>\n",
    "4. Split the dataset into training, validation, and test sets  \n",
    "<br>\n",
    "5. Prepare dataset objects containing input tokens and corresponding labels  \n",
    "<br>\n",
    "6. Initialize DataLoaders to batch and load the data efficiently during training  \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a1edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6adeeba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "\n",
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)\n",
    "\n",
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a963749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8c7f164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a034c62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9231cb",
   "metadata": {},
   "source": [
    "## Model initialization with the Pre-trained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9039b382",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-warning\">\n",
    "1. Use gpt architecture\n",
    "<br>\n",
    "2. Use pre-trained gpt-2 weights\n",
    "<br>\n",
    "3. Freeze almost all layers inorder to prevent updates to preserve pretrained knowledge.\n",
    "<br>\n",
    "4. Replace the final output with the classification head\n",
    "<br>\n",
    "5. Unfreeze the last layer\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3e0c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dab7eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "\n",
    "    ###Input batch:\n",
    " ###tensor([[6109, 3626, 6100,  345],\n",
    "        ##[6109, 1110, 6622,  257]])\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx\n",
    "\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n",
    "            GELU(), ## Activation\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        # 2*4*768\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x\n",
    "        # 2*4*768\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "\n",
    "\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d819d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b43b9ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SATHVIK\\anaconda3\\envs\\medibot\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SATHVIK\\anaconda3\\envs\\medibot\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SATHVIK\\anaconda3\\envs\\medibot\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SATHVIK\\anaconda3\\envs\\medibot\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SATHVIK\\anaconda3\\envs\\medibot\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SATHVIK\\anaconda3\\envs\\medibot\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SATHVIK\\anaconda3\\envs\\medibot\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "from gpt_download3 import download_and_load_gpt2\n",
    "\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ca58ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecc5319",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Now, before we start finetuning the model as a spam classifier, let's see if the model can\n",
    "perhaps already classify spam messages by by prompting it with instructions:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a422762c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4de9e1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Based on the output, it's apparent that the model struggles with following instructions.\n",
    "\n",
    "This is anticipated, as it has undergone only pretraining and lacks instruction-finetuning,\n",
    "which we will explore in the upcoming chapter\n",
    "\n",
    "The next section prepares the model for classification-finetuning\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a8886d",
   "metadata": {},
   "source": [
    "## Add Classification head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b944c46",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-warning\">\n",
    "1. Every token generates two output\n",
    "<br>\n",
    "(1 * 12 * 768) -> (1 * 12 * 2)\n",
    "<br>\n",
    "2. Softmax\n",
    "<br>\n",
    "3. give the argmax\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fd21a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68600f04",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "To get the model ready for classification-finetuning, we first freeze the model, meaning that\n",
    "we make all layers non-trainable:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0d769f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c1f11a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "## 768 * 50257 -> 768 * 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1d836dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2d321ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c34d0b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9238e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c59c2d",
   "metadata": {},
   "source": [
    "## Calculating the classification loss and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3078f0f0",
   "metadata": {},
   "source": [
    " <div class = \"alert alert-block alert-info\">\n",
    " Loss function = summation of (Yi log Pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9312bdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ef378e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636ef78d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "In this case, the code returns 1, meaning the model predicts that the input text is \"spam.\"\n",
    "\n",
    "Using the softmax function here is optional because the largest outputs directly correspond\n",
    "to the highest probability scores. \n",
    "\n",
    "Hence, we can simplify the\n",
    "code as follows, without using softmax:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ea255c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1daa91cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
    "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#print(f\"Running on {device} device.\")\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32cb3cd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "As we can see, the prediction accuracies are near a random prediction, which would be\n",
    "50% in this case. \n",
    "\n",
    "To improve the prediction accuracies, we need to finetune the model.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d7175f",
   "metadata": {},
   "source": [
    "cross-entrophy does the softmax and -log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78b9bcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5de30d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in chapter 5\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "168f0054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e7d33",
   "metadata": {},
   "source": [
    "## FINETUNING THE MODEL ON SUPERVISED DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc16da4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "Step 1: Set model to training mode\n",
    "\n",
    "Step 2: Reset loss gradients from previous batch iteration\n",
    "\n",
    "Step 3: Calculate loss gradients\n",
    "\n",
    "Step 4: Update model weights using loss gradients\n",
    "\n",
    "Step 5: New: track examples instead of tokens\n",
    "\n",
    "Step 6: Optional evaluation step\n",
    "\n",
    "Step 7: Calculate accuracy after each epoch\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a53ae59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall the same as `train_model_simple` in chapter 5\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2fc9d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8882b14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
      "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
      "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
      "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 17.05 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01f2dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba97353e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "As we can see based on the sharp downward slope, the model is learning well\n",
    "from the training data, and there is little to no indication of overfitting; that is, there is no\n",
    "noticeable gap between the training and validation set losses).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3ea85bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2683aa45",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Based on the accuracy plot in figure 6.17, the model achieves a relatively high training and\n",
    "validation accuracy after epochs 4 and 5.\n",
    "    \n",
    "However, it's important to note that we previously set eval_iter=5 when using the\n",
    "train_classifier_simple function, which means our estimations of training and\n",
    "validation performance were based on only 5 batches for efficiency during training.\n",
    "\n",
    "Now, we will calculate the performance metrics for the training, validation, and test sets\n",
    "across the entire dataset by running the following code, this time without defining the\n",
    "eval_iter value:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30222191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.21%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc31129",
   "metadata": {},
   "source": [
    "## USING THE LLM AS A SPAM CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50d3942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cabce97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5307a654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81e639c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cf12316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
